{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face Mask Detector.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnCy5V638gwN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "05446d35-d537-48c6-b081-c2cc1118f648"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import argparse\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phF756mmJGJ5",
        "colab_type": "text"
      },
      "source": [
        "### **IMPORTANT NOTE:**\n",
        "#### If you take a look at Figure you can start to see our training and validation loss start to rapidly divide. When you see training loss falling quickly while validation loss stagnates or even increases, you know you are overfitting.\n",
        "\n",
        "![alt text](https://pyimagesearch.com/wp-content/uploads/2019/06/unfrozen.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YVnwF9usVzm",
        "colab_type": "text"
      },
      "source": [
        "## What Is **MobileNetV2**?\n",
        "#### MobileNets are small, low-latency, low-power models parameterised to meet the resource constraints of a variety of use cases. According to the research paper, MobileNetV2 improves the state-of-the-art performance of mobile models on multiple tasks and benchmarks as well as across a spectrum of different model sizes.\n",
        "#### MobileNetV2 is optimised for mobile devices. The architecture delivers high accuracy results while keeping the parameters and mathematical operations as low as possible to bring deep neural networks to mobile devices.\n",
        "#### The weights of the pre-trained snippets were learned by the Google team using **ImageNet**.\n",
        "#### NOTE: **Weights in MobileNetV2:** \n",
        "\n",
        "One of the following:\n",
        "*   None (random initialization)\n",
        "*   'imagenet' (pre-training on ImageNet)\n",
        "*   or the path to the weights file to be loaded. Default to imagenet.\n",
        "\n",
        "---\n",
        "#### To accomplish **FACE MASK DETECTOR**, we’ll be fine-tuning the MobileNet V2 architecture, a highly efficient architecture that can be applied to embedded devices with limited computational capacity (ex., Raspberry Pi, Google Coral, NVIDIA Jetson Nano, etc.).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gn7a_St2wacz",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Parsing a few command line arguments that are required to launch our script from a terminal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IW2Sl1cx8-TT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ap = argparse.ArgumentParser()\n",
        "# ap.add_argument(\"-d\", \"--dataset\", required=True,\n",
        "# \thelp=\"path to input dataset\")\n",
        "# ap.add_argument(\"-p\", \"--plot\", type=str, default=\"plot.png\",\n",
        "# \thelp=\"path to output loss/accuracy plot\")\n",
        "# ap.add_argument(\"-m\", \"--model\", type=str,\n",
        "# \tdefault=\"mask_detector.model\",\n",
        "# \thelp=\"path to output face mask detector model\")\n",
        "# args = vars(ap.parse_args())"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yK1TYqbzw9zK",
        "colab_type": "text"
      },
      "source": [
        "## Defining Hyperparameters\n",
        "#### We will be applying a learning rate decay schedule, which is why we’ve named the learning rate variable INIT_LR."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e9GCdKrwtia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init_lr = 1e-4  # 0.0001\n",
        "epochs = 20\n",
        "bs = 32"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDryDXzTxQ4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}